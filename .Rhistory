library(readr)
CWTme_mh_APO_001_CWT_features <- read_csv("Documents/Thesis-Stroke/StatisticalAnalysis/CWT/CWTme_mh_APO-001_CWT_features.csv")
View(CWTme_mh_APO_001_CWT_features)
data <- CWTme_mh_APO_001_CWT_features
install.packages('dplyr')
library(dplyr)
data$Label <- factor(data$Label)
data$Stage <- factor(data$Stage)
tst <- data[data$Stage == '1', data$Freq_name = 'Delta']
tst <- data[data$Stage == '1', data$Freq_name == 'Delta',]
tst <- data[data$Stage == '1' & data$Freq_name == 'Delta',]
tst.mean <- group_by(data = tst, add = 'mean')
tst.mean <- group_by(.data = data)
tst.mean <- group_by(.data = data, add = mean())
tst.mean <- group_by(.data = data, add = mean
)
tst.mean <- group_by(.data = data, add = 'mean')
aggregate(x = data, by = list(ID_pat = data$ID_pat, Stage = data$Stage, Chann_name = data$Chann_name, Freq_name = data$Freq_name), FUN = mean)
data.agg <- aggregate(x = data, by = list(ID_pat = data$ID_pat, Stage = data$Stage, Chann_name = data$Chann_name, Freq_name = data$Freq_name), FUN = mean)
View(data.agg)
data$Chann_name <- factor(data$Chann_name)
data$ID_pat <- factor(data$ID_pat)
data$Freq_name <- factor(data$Freq_name)
data.agg <- aggregate(x = data, by = list(ID_pat = data$ID_pat, Stage = data$Stage, Chann_name = data$Chann_name, Freq_name = data$Freq_name), FUN = mean)
View(data.agg)
data.agg <- aggregate(x = data, by = list(data$Freq_name, data$ID_pat, data$Stage, data$Chann_name), FUN = mean)
library(readr)
me_mh_APO_001_CWT_features <- read_csv("Downloads/me_mh_APO-001_CWT_features.csv")
View(me_mh_APO_001_CWT_features)
CWTme_mh_APO_001_CWT_features$Chann_name <- factor(CWTme_mh_APO_001_CWT_features$Chann_name)
install.packages('xlsx')
install.packages('xlsxjars')
install.packages('xlsx')
setInternet2(use=TRUE)
install.packages('rJava')
remove.packages("rJava")
install.packages('rJava')
install.packages('rJava')
install.packages('xlsx')
# Import libraries
library(jsonlite)
library(tidyverse)
library(readr)
library(data.table)
library(ggrepel)
library(viridis)
library(hrbrthemes)
library(HIBAG)
library(parallel)
library(corrplot)
library(randomForest)
library(xlsx)
install.packages('xlsx')
install.packages('xlsxjars')
install.packages('xlsxjars')
install.packages('rJava')
library(rJava)
remove.packages('rJava')
remove.packages(rJava)
install.packages('rJava')
install.packages('rJava')
library(rJava)
library(rJava)
library(rJava)
install.packages('rJava')
install.packages('rJava')
install.packages('rJava')
locate getsp
install.packages('rJava')
remove.packages('rJava')
library(rJava)
install.packages('rJava')
# Import libraries
library(jsonlite)
library(tidyverse)
# Import libraries
library(jsonlite)
library(tidyverse)
library(readr)
library(data.table)
library(ggrepel)
library(viridis)
library(hrbrthemes)
library(HIBAG)
library(parallel)
library(corrplot)
library(randomForest)
library(xlsx)
# Import libraries
library(jsonlite)
library(tidyverse)
library(readr)
library(data.table)
library(ggrepel)
library(viridis)
library(hrbrthemes)
library(HIBAG)
library(parallel)
library(corrplot)
library(randomForest)
library(xlsx)
library(TreeBH)
library(zeallot)
library(epitools)
# Set working directory
setwd("~/Documents/Alzheimer-Disease")
# Import settings
settings <- jsonlite::read_json("settings.json")
# Set values to 0
settings$controlAlleles <- c()
settings$excludePosSubjsByAllele <- c()
settings$allele2Remove <- c()
# Create comand
`%notin%` <- Negate(`%in%`)
# Import HLA calls and covariates
HLA.df <- read.csv(settings$file$HLA_df)
covars.df <- read.csv(settings$file$HLA_covars_filt)
covars.df$pheno <- covars.df$pheno -1
covars.df$sex <- covars.df$sex -1
# Add phenotype to HLA datafra,e
HLA.df <- merge(HLA.df, covars.df[,c("sample.id.file", "pheno")], by = "sample.id.file")
# Import amino acid alignment
AA_alignment <- read.table(settings$file$AA_alignment, header = TRUE, sep = ',')
# Remove negative positions
full_prot = FALSE
if (!full_prot){
AA_alignment[,3] <- AA_alignment %>% apply(MARGIN = 1, function(x) x[3] %>% substr(start = 30, stop = nchar(x[3])))
}
# Loci
L <- "DBR1"
# Get locus ID
c(A1, A2) %<-% c(paste0(L,'.1'), paste0(L,'.2'))
# Get alignment subset, and counts subset
AA_locus <- AA_alignment %>% filter(locus == L)
# Get max sequence length
maxLen <- AA_locus$sequence %>% lapply(nchar) %>% unlist() %>% max()
# Get unique AAs
AAOHE <- data.frame("sample.id" = HLA.df$sample.id)
# Loci
L <- "DBR1"
# Get locus ID
c(A1, A2) %<-% c(paste0(L,'.1'), paste0(L,'.2'))
# Get alignment subset, and counts subset
AA_locus <- AA_alignment %>% filter(locus == L)
# Get max sequence length
maxLen <- AA_locus$sequence %>% lapply(nchar) %>% unlist() %>% max()
maxLen
AA_locus
data2OHE = function(settings, data, allelesAA, covars.df, AA_alignment){
# Get data with AAs
data.AApos <- data %>% filter(get(A1) %in% allelesAA| get(A2) %in% allelesAA)
data.AAneg <- data %>% filter(sample.id.file %notin% data.AApos$sample.id.file)
# Create dataframe with OHE
data.AA <- data.frame(sample.id.file = c(data.AApos$sample.id.file, data.AAneg$sample.id.file), AA = c(rep(1, nrow(data.AApos)), rep(0, nrow(data.AAneg))))
# Merge with presence of controlled amino acid
if (!settings$AA2control %>% is_empty()){
data.AAcontrol <- controlAA(settings, data, AA_alignment)
data.AA <- merge(data.AA, data.AAcontrol, by = "sample.id.file")
}
# Return
return(data.AA)
}
# Loci
L <- "DRB1"
# Get locus ID
c(A1, A2) %<-% c(paste0(L,'.1'), paste0(L,'.2'))
# Get alignment subset, and counts subset
AA_locus <- AA_alignment %>% filter(locus == L)
# Get max sequence length
maxLen <- AA_locus$sequence %>% lapply(nchar) %>% unlist() %>% max()
# Get unique AAs
AAOHE <- data.frame("sample.id" = HLA.df$sample.id)
for (pos in 1:maxLen){
# Get unique AAs
AAs <- AA_locus$sequence %>% lapply(function(x, pos) substr(x, pos, pos), pos) %>% unlist() %>% unique()
AAs <- AAs[which(AAs != '' & AAs!= '*')]
# For each AA
for (AA in AAs){
# Get alleles with AAs
allelesAA.OG <- AA_locus %>% apply(MARGIN = 1, function(x, pos, AA) if (substr(x[3],pos,pos) == AA) {return(x[2])}, pos, AA) %>% unlist()
allelesAA <- allelesAA.OG %>% lapply(function(x) strsplit(x, split='\\*') %>% unlist() %>%
.[2] %>% strsplit(split=':') %>% unlist() %>% .[1:2] %>% paste(collapse=':')) %>% unlist()
# Crete one hot encoding dataframes
data.AA <- data2OHE(settings, HLA.df, allelesAA, covars.df, AA_alignment); colnames(data.AA)[2] <- paste(L,pos,AA, sep = '_')
# Merge
AAOHE <- cbind(AAOHE, data.AA)
}
}
# Get unique AAs
AAOHE <- data.frame("sample.id" = HLA.df$sample.id, "sample.id.file" = HLA.df$sample.id.file)
# Loci
L <- "DRB1"
# Get locus ID
c(A1, A2) %<-% c(paste0(L,'.1'), paste0(L,'.2'))
# Get alignment subset, and counts subset
AA_locus <- AA_alignment %>% filter(locus == L)
# Get max sequence length
maxLen <- AA_locus$sequence %>% lapply(nchar) %>% unlist() %>% max()
# Get unique AAs
AAOHE <- data.frame("sample.id" = HLA.df$sample.id, "sample.id.file" = HLA.df$sample.id.file)
for (pos in 1:maxLen){
# Get unique AAs
AAs <- AA_locus$sequence %>% lapply(function(x, pos) substr(x, pos, pos), pos) %>% unlist() %>% unique()
AAs <- AAs[which(AAs != '' & AAs!= '*')]
# For each AA
for (AA in AAs){
# Get alleles with AAs
allelesAA.OG <- AA_locus %>% apply(MARGIN = 1, function(x, pos, AA) if (substr(x[3],pos,pos) == AA) {return(x[2])}, pos, AA) %>% unlist()
allelesAA <- allelesAA.OG %>% lapply(function(x) strsplit(x, split='\\*') %>% unlist() %>%
.[2] %>% strsplit(split=':') %>% unlist() %>% .[1:2] %>% paste(collapse=':')) %>% unlist()
# Crete one hot encoding dataframes
data.AA <- data2OHE(settings, HLA.df, allelesAA, covars.df, AA_alignment); colnames(data.AA)[2] <- paste(L,pos,AA, sep = '_')
# Merge
AAOHE <- merge(AAOHE, data.AA, by ="sample.id.file")
}
}
# Wrie
write.table(AAOHE, file = "Outputs/OHE_AA/OHE_AA.csv", sep = ",", quote = FALSE, row.names = FALSE, col.names = TRUE)
library(jsonlite)
library(xlsx)
library(dplyr)
# Set working directory
setwd("~/Documents/Alzheimer-Disease")
# Import settings
settings <- jsonlite::read_json("settings.json")
# Create comand
`%notin%` <- Negate(`%in%`)
# Import covariates
covars.df <- read.csv(settings$file$HLA_covars, sep = '\t')
covars.df$file.origin <- covars.df$FID %>% lapply(function(x) gsub('[[:digit:]]+', '', x %>% strsplit('_') %>% unlist() %>% .[1])) %>% unlist()
covars.df$sample.id.file <- paste0(covars.df$file.origin,'_', covars.df$IID)
# Import relatedness
relat.df <- read.csv(settings$file$relatedness_df)
### Remove duplicate Ids
# Load HLA file
HLACalls_names <- list.files(settings$folder$HLACalls)
HLA.df <- read.csv(paste0(settings$folder$HLACalls,HLACalls_names[1]));
# Create new variables
HLA.df$file.origin <- HLA.df$fileName %>% lapply(function(x) gsub('[[:digit:]]+', '', x %>% strsplit('_') %>% unlist() %>% .[1])) %>% unlist()
HLA.df$sample.id.file <- paste0(HLA.df$file.origin,'_', HLA.df$sample.id)
HLA.df <- HLA.df[c(1,7,8,2,3)]
# Merge
for (file in HLACalls_names[2:length(HLACalls_names)]){
print(paste0('Current iteration: ', file))
# Load and create new variables
df_loop <- read.csv(paste0(settings$folder$HLACalls, file));
df_loop$file.origin <- df_loop$fileName %>% lapply(function(x) gsub('[[:digit:]]+', '', x %>% strsplit('_') %>% unlist() %>% .[1])) %>% unlist()
df_loop$sample.id.file <- paste0(df_loop$file.origin,'_', df_loop$sample.id)
# Remove duplcates
df_loop <- df_loop %>% distinct(sample.id.file, .keep_all = TRUE)
df_loop <- df_loop[c(1,7,8,2,3)]
# Merge
HLA.df <- merge(HLA.df, df_loop[-c(1:2)], by.x = 'sample.id.file', by.y = 'sample.id.file', all = TRUE)
}
# CHECK: NAs
missHLA <- HLA.df[which(is.na(HLA.df), arr.ind=TRUE),]
HLA.df.filt <- HLA.df
# Remove duplicates based on alleles, and sample.id.file
HLA.df.filt <- HLA.df.filt %>% distinct(sample.id.file, .keep_all = TRUE)
# Filter relatedness
related.df.filt <- relat.df %>% filter(ID1 %in% HLA.df.filt$sample.id & ID2 %in% HLA.df.filt$sample.id)
# Count duplicates
rel.dup.df <- related.df.filt %>% filter(InfType == 'Dup/MZ')
# Remove duplicates
pairs.df <- data.frame(id1 = c(), id2 = c())
for (i in 1:nrow(rel.dup.df)){
# Get ID1 and ID2
id1 <- paste0(rel.dup.df$FID1 %>% lapply(function(x) gsub('[[:digit:]]+', '', x %>% strsplit('_') %>% unlist() %>% .[1])) %>% unlist() %>% .[i],
"_",rel.dup.df$ID1[i]);
id2 <- paste0(rel.dup.df$FID2 %>% lapply(function(x) gsub('[[:digit:]]+', '', x %>% strsplit('_') %>% unlist() %>% .[1])) %>% unlist() %>% .[i]
,"_",rel.dup.df$ID2[i]);
# Filter
df <- HLA.df.filt %>% filter(sample.id.file %in% c(id1, id2))
# Check if identical
if (any(duplicated(df[,c(4:23)]) == TRUE)){
# Keep pair
pairs.df <- rbind(pairs.df, data.frame(id1 = id1, id2 = id2))
}
}
# Write
write.csv(HLA.df.filt, file = settings$file$HLA_df, row.names = FALSE)
View(HLA.df.filt)
# Import libraries
library(jsonlite)
library(tidyverse)
library(readr)
library(data.table)
library(ggrepel)
library(viridis)
library(hrbrthemes)
library(HIBAG)
library(parallel)
library(corrplot)
library(randomForest)
library(xlsx)
library(TreeBH)
library(zeallot)
library(epitools)
# Set working directory
setwd("~/Documents/Alzheimer-Disease")
# Import settings
settings <- jsonlite::read_json("settings.json")
# Set values to 0
settings$controlAlleles <- c()
settings$excludePosSubjsByAllele <- c()
settings$allele2Remove <- c()
# Create comand
`%notin%` <- Negate(`%in%`)
# Import HLA calls and covariates
HLA.df <- read.csv(settings$file$HLA_df)
View(HLA.df)
covars.df <- read.csv(settings$file$HLA_covars_filt)
covars.df$pheno <- covars.df$pheno -1
covars.df$sex <- covars.df$sex -1
# Add phenotype to HLA datafra,e
HLA.df <- merge(HLA.df, covars.df[,c("sample.id.file", "pheno")], by = "sample.id.file")
# Import amino acid alignment
AA_alignment <- read.table(settings$file$AA_alignment, header = TRUE, sep = ',')
# Remove negative positions
full_prot = FALSE
if (!full_prot){
AA_alignment[,3] <- AA_alignment %>% apply(MARGIN = 1, function(x) x[3] %>% substr(start = 30, stop = nchar(x[3])))
}
data2OHE = function(settings, data, allelesAA, covars.df, AA_alignment){
# Get data with AAs
data.AApos <- data %>% filter(get(A1) %in% allelesAA| get(A2) %in% allelesAA)
data.AAneg <- data %>% filter(sample.id.file %notin% data.AApos$sample.id.file)
# Create dataframe with OHE
data.AA <- data.frame(sample.id.file = c(data.AApos$sample.id.file, data.AAneg$sample.id.file), AA = c(rep(1, nrow(data.AApos)), rep(0, nrow(data.AAneg))))
# Merge with presence of controlled amino acid
if (!settings$AA2control %>% is_empty()){
data.AAcontrol <- controlAA(settings, data, AA_alignment)
data.AA <- merge(data.AA, data.AAcontrol, by = "sample.id.file")
}
# Return
return(data.AA)
}
# Loci
L <- "DRB1"
# Get locus ID
c(A1, A2) %<-% c(paste0(L,'.1'), paste0(L,'.2'))
# Get alignment subset, and counts subset
AA_locus <- AA_alignment %>% filter(locus == L)
# Get max sequence length
maxLen <- AA_locus$sequence %>% lapply(nchar) %>% unlist() %>% max()
# Get unique AAs
AAOHE <- data.frame("sample.id" = HLA.df$sample.id, "sample.id.file" = HLA.df$sample.id.file)
for (pos in 1:maxLen){
# Get unique AAs
AAs <- AA_locus$sequence %>% lapply(function(x, pos) substr(x, pos, pos), pos) %>% unlist() %>% unique()
AAs <- AAs[which(AAs != '' & AAs!= '*')]
# For each AA
for (AA in AAs){
# Get alleles with AAs
allelesAA.OG <- AA_locus %>% apply(MARGIN = 1, function(x, pos, AA) if (substr(x[3],pos,pos) == AA) {return(x[2])}, pos, AA) %>% unlist()
allelesAA <- allelesAA.OG %>% lapply(function(x) strsplit(x, split='\\*') %>% unlist() %>%
.[2] %>% strsplit(split=':') %>% unlist() %>% .[1:2] %>% paste(collapse=':')) %>% unlist()
# Crete one hot encoding dataframes
data.AA <- data2OHE(settings, HLA.df, allelesAA, covars.df, AA_alignment); colnames(data.AA)[2] <- paste(L,pos,AA, sep = '_')
# Merge
AAOHE <- merge(AAOHE, data.AA, by ="sample.id.file")
}
}
# Wrie
write.table(AAOHE, file = "Outputs/OHE_AA/OHE_AA.csv", sep = ",", quote = FALSE, row.names = FALSE, col.names = TRUE)
View(HLA.df)
# Import HLA calls and covariates
HLA.df <- read.csv(settings$file$HLA_df)
# Import amino acid alignment
AA_alignment <- read.table(settings$file$AA_alignment, header = TRUE, sep = ',')
# Remove negative positions
full_prot = FALSE
if (!full_prot){
AA_alignment[,3] <- AA_alignment %>% apply(MARGIN = 1, function(x) x[3] %>% substr(start = 30, stop = nchar(x[3])))
}
data2OHE = function(settings, data, allelesAA, covars.df, AA_alignment){
# Get data with AAs
data.AApos <- data %>% filter(get(A1) %in% allelesAA| get(A2) %in% allelesAA)
data.AAneg <- data %>% filter(sample.id.file %notin% data.AApos$sample.id.file)
# Create dataframe with OHE
data.AA <- data.frame(sample.id.file = c(data.AApos$sample.id.file, data.AAneg$sample.id.file), AA = c(rep(1, nrow(data.AApos)), rep(0, nrow(data.AAneg))))
# Merge with presence of controlled amino acid
if (!settings$AA2control %>% is_empty()){
data.AAcontrol <- controlAA(settings, data, AA_alignment)
data.AA <- merge(data.AA, data.AAcontrol, by = "sample.id.file")
}
# Return
return(data.AA)
}
# Loci
L <- "DRB1"
# Get locus ID
c(A1, A2) %<-% c(paste0(L,'.1'), paste0(L,'.2'))
# Get alignment subset, and counts subset
AA_locus <- AA_alignment %>% filter(locus == L)
# Get max sequence length
maxLen <- AA_locus$sequence %>% lapply(nchar) %>% unlist() %>% max()
# Get unique AAs
AAOHE <- data.frame("sample.id" = HLA.df$sample.id, "sample.id.file" = HLA.df$sample.id.file)
for (pos in 1:maxLen){
# Get unique AAs
AAs <- AA_locus$sequence %>% lapply(function(x, pos) substr(x, pos, pos), pos) %>% unlist() %>% unique()
AAs <- AAs[which(AAs != '' & AAs!= '*')]
# For each AA
for (AA in AAs){
# Get alleles with AAs
allelesAA.OG <- AA_locus %>% apply(MARGIN = 1, function(x, pos, AA) if (substr(x[3],pos,pos) == AA) {return(x[2])}, pos, AA) %>% unlist()
allelesAA <- allelesAA.OG %>% lapply(function(x) strsplit(x, split='\\*') %>% unlist() %>%
.[2] %>% strsplit(split=':') %>% unlist() %>% .[1:2] %>% paste(collapse=':')) %>% unlist()
# Crete one hot encoding dataframes
data.AA <- data2OHE(settings, HLA.df, allelesAA, covars.df, AA_alignment); colnames(data.AA)[2] <- paste(L,pos,AA, sep = '_')
# Merge
AAOHE <- merge(AAOHE, data.AA, by ="sample.id.file")
}
}
# Wrie
write.table(AAOHE, file = "Outputs/OHE_AA/OHE_AA.csv", sep = ",", quote = FALSE, row.names = FALSE, col.names = TRUE)
